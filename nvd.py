# Author: Visshwanth Reddy
# Script to download nvd dataset and create a CSV file

import requests
import re
import os
import glob
import bs4 as bs
import pandas as pd
import json

# Function fetch specified file and save it to the specified directory
def DownLoadFile(url, dataDir):
	try:
		# Fetch file and save it to the specified dir
		print 'Fetching:', url
		response = requests.get(url)
		fileName = re.sub('.*/','',url)
		fileName = dataDir + '/' + fileName
		dataFile = open(fileName, 'wb')
		dataFile.write(response.content)
		datafile.close()
		# Unzip file
		resp = os.system('unzip {} -d {}'.format(fileName, dataDir))
		os.remove(fileName)
	except:
		print 'Error fetching file:', url

# Function to extract zip file urls from specified page 
def NVDFileList(url):
	fileList = []
	# Fetch html page
	print 'Fetching:', url
	response = requests.get(url)
	page = bs.BeautifulSoup(response.text, 'lxml')
	# Extract all links with text 'ZIP' on the page
	urlData = page.findAll('a', href=True, text='ZIP')
	for url in urlData:
		fileName = url['href']
		if fileName.find('json.zip') > 0:
			if (fileName.find('modified') < 0) & (fileName.find('recent') < 0):
				fileList.append(fileName)
	return sorted(fileList)

# Function for loading JSON file
def LoadJSONFile(fileName):
	with open(fileName) as f:
		data = json.load(f)
	
	return data

# Function for creating the NVD data set after parsing through the specified set of JSON files
def CreateNVDDataSet(dataDir, filePattern, exploitDBFile):
	fileList = glob.glob('{}/{}*.json'.format(dataDir,filePattern))
	exploitDB = LoadJSONFile('{}/{}'.format(dataDir,exploitDBFile))
	nvdData = []
	cveList = []
	for each in fileList:
		print 'Processing:', each
		data = LoadJSONFile(each)
		cveData = data['CVE_Items']
		for cve in cveData:
			ID = cve['cve']['CVE_data_meta']['ID']
			try:
				VEN = len(cve['cve']['affects']['vendor']['vendor_data'])
			except:
				VEN = 0
			try:
				DESC = cve['cve']['description']['description_data'][0]['value']
			except:
				DESC = ''
			if len(cve['impact'].keys()) != 0:
				AV = cve['impact']['baseMetricV2']['cvssV2']['accessVector']
				AC = cve['impact']['baseMetricV2']['cvssV2']['accessComplexity']
				A = cve['impact']['baseMetricV2']['cvssV2']['authentication']
				CI = cve['impact']['baseMetricV2']['cvssV2']['confidentialityImpact']
				II = cve['impact']['baseMetricV2']['cvssV2']['integrityImpact']
				AI = cve['impact']['baseMetricV2']['cvssV2']['availabilityImpact']
				BS = cve['impact']['baseMetricV2']['cvssV2']['baseScore']
				S = cve['impact']['baseMetricV2']['severity']
				ES = cve['impact']['baseMetricV2']['exploitabilityScore']
				IS = cve['impact']['baseMetricV2']['impactScore']
				OAP = cve['impact']['baseMetricV2']['obtainAllPrivilege']
				OUP = cve['impact']['baseMetricV2']['obtainUserPrivilege']
				OOP = cve['impact']['baseMetricV2']['obtainOtherPrivilege']
				try:
					UIR = cve['impact']['baseMetricV2']['userInteractionRequired']
				except:
					UIR = False
			else:
				AV,AC,A,CI,II,AI,BS,S,ES,IS,OAP,OUP,OOP,UIR = '','','','','','','','','','','','','',''
			try:
				E = exploitDB[ID]
				E = 1
			except:
				E = 0
			nvdData.append({'ID':ID,'E':E,'AV':AV,'AC':AC,'A':A,'CI':CI,'II':II,'AI':AI,'BS':BS,'S':S,'ES':ES,'IS':IS,'OAP':OAP,'OUP':OUP,'OOP':OOP,'UIR':UIR,'VEN':VEN,'DESC':DESC})
			cveList.append(ID)
	nvdDF = pd.DataFrame(nvdData)
	cols = ['ID','E','AV','AC','A','CI','II','AI','BS','S','ES','IS','OAP','OUP','OOP','UIR','VEN','DESC']
	nvdDF = nvdDF[cols]
	nvdDF.to_csv('nvd_data.csv', index=False, encoding='utf-8')

###############################################################	

# Main

dataDir = 'data'
nvdURL = 'https://nvd.nist.gov/vuln/data-feeds'
exploitDBFile = 'exploitdb_mapping_cve.json'

# Creating a list of files to fetch to create the NVD dataset
fileList = NVDFileList(nvdURL)

# Fetching files
for fileURL in fileList:
	DownLoadFile(fileURL, dataDir)

filePattern = 'nvdcve'
# Creating the NVD dataset
CreateNVDDataSet(dataDir, filePattern, exploitDBFile)

